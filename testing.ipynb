{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for file: C:/Users/saich/Downloads/TSS zip/TSS/Mycobacterium tuberculosis H37Rv.txt\n",
      "         Classifier Pos_Range Neg_Range  Accuracy  Precision   Recall  F1 Score                       Name\n",
      "                SVM   350-500   600-750  0.623413   0.614610 0.681564  0.646358 Synechocystis sp. PCC 6803\n",
      "      Random Forest   350-500   600-750  0.638928   0.646552 0.628492  0.637394 Synechocystis sp. PCC 6803\n",
      "Logistic Regression   350-500   600-750  0.612130   0.613699 0.625698  0.619640 Synechocystis sp. PCC 6803\n",
      "        Naive Bayes   350-500   600-750  0.599436   0.586854 0.698324  0.637755 Synechocystis sp. PCC 6803\n",
      "               K-NN   350-500   600-750  0.504937   0.509915 0.502793  0.506329 Synechocystis sp. PCC 6803\n",
      "  Gradient Boosting   350-500   600-750  0.638928   0.644886 0.634078  0.639437 Synechocystis sp. PCC 6803\n",
      "           AdaBoost   350-500   600-750  0.622003   0.625698 0.625698  0.625698 Synechocystis sp. PCC 6803\n",
      "      Decision Tree   350-500   600-750  0.578279   0.578667 0.606145  0.592087 Synechocystis sp. PCC 6803\n",
      "         Perceptron   350-500   600-750  0.575458   0.579832 0.578212  0.579021 Synechocystis sp. PCC 6803\n",
      "                SGD   350-500   600-750  0.586742   0.592593 0.581006  0.586742 Synechocystis sp. PCC 6803\n",
      "            Bagging   350-500   600-750  0.614951   0.628399 0.581006  0.603774 Synechocystis sp. PCC 6803\n",
      "        Extra Trees   350-500   600-750  0.599436   0.603352 0.603352  0.603352 Synechocystis sp. PCC 6803\n",
      "           CatBoost   350-500   600-750  0.612130   0.613079 0.628492  0.620690 Synechocystis sp. PCC 6803\n",
      "           LightGBM   350-500   600-750  0.610719   0.614525 0.614525  0.614525 Synechocystis sp. PCC 6803\n",
      "            XGBoost   350-500   600-750  0.617772   0.626822 0.600559  0.613409 Synechocystis sp. PCC 6803\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron, SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import glob\n",
    "from itertools import product\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def transform_sequence(sequence):\n",
    "    length = len(sequence)\n",
    "    total1 = 0\n",
    "    for i in range(length - 1):\n",
    "        sequence2 = sequence[i + 1:]\n",
    "        length2 = len(sequence2)\n",
    "        count1 = sum(1 for j in range(length2) if sequence[j] == sequence2[j])\n",
    "        total1 += (count1 % length2) * 100\n",
    "    \n",
    "    total1 = (total1 / (length - 1)) * 100 if length > 1 else 0\n",
    "    return total1\n",
    "\n",
    "def generate_trimers():\n",
    "    bases = ['A', 'C', 'G', 'T']\n",
    "    return [''.join(p) for p in product(bases, repeat=3)]\n",
    "\n",
    "def transform_sequence_kmer(sequence):\n",
    "    return [transform_sequence(sequence[i:i + 6]) for i in range(len(sequence) - 6)]\n",
    "\n",
    "def load_and_transform_data(file_path, pos_range, neg_range):\n",
    "    with open(file_path, 'r') as file:\n",
    "        sequences = file.read().split('\\n')\n",
    "    pos_sequences = [seq[pos_range[0]-1:pos_range[1]] for seq in sequences if len(seq) >= pos_range[1]]\n",
    "    neg_sequences = [seq[neg_range[0]-1:neg_range[1]] for seq in sequences if len(seq) >= neg_range[1]]\n",
    "    pos_data = pd.DataFrame([transform_sequence_kmer(seq) for seq in pos_sequences])\n",
    "    neg_data = pd.DataFrame([transform_sequence_kmer(seq) for seq in neg_sequences])\n",
    "    \n",
    "    pos_data['label'] = 1\n",
    "    neg_data['label'] = 0\n",
    "    data = pd.concat([pos_data, neg_data], ignore_index=True)\n",
    "    \n",
    "    # Ensure the dataframe contains only numerical values\n",
    "    X = np.array(data.drop('label', axis=1).values.tolist())\n",
    "    y = data['label'].values\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def evaluate_classifiers(file_path, combinations, classifiers):\n",
    "    results = []\n",
    "    \n",
    "    for pos_range, neg_range in combinations:\n",
    "        X, y = load_and_transform_data(file_path, pos_range, neg_range)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)\n",
    "        \n",
    "        for name, clf in classifiers.items():\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            \n",
    "            results.append({\n",
    "                'Classifier': name,\n",
    "                'Pos_Range': f\"{pos_range[0]}-{pos_range[1]}\",\n",
    "                'Neg_Range': f\"{neg_range[0]}-{neg_range[1]}\",\n",
    "                'Accuracy': accuracy_score(y_test, y_pred),\n",
    "                'Precision': precision_score(y_test, y_pred, zero_division=0),\n",
    "                'Recall': recall_score(y_test, y_pred, zero_division=0),\n",
    "                'F1 Score': f1_score(y_test, y_pred, zero_division=0),\n",
    "                'Name': 'Synechocystis sp. PCC 6803'\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Classifier definitions\n",
    "classifiers = {\n",
    "    'SVM': SVC(probability=True, random_state=101),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=101, n_jobs=-1),\n",
    "    'Logistic Regression': LogisticRegression(random_state=101, max_iter=500),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'K-NN': KNeighborsClassifier(n_neighbors=5),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=101),\n",
    "    'AdaBoost': AdaBoostClassifier(n_estimators=100, random_state=101),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=101),\n",
    "    'Perceptron': Perceptron(random_state=101),\n",
    "    'SGD': SGDClassifier(random_state=101),\n",
    "    'Bagging': BaggingClassifier(n_estimators=100, random_state=101),\n",
    "    'Extra Trees': ExtraTreesClassifier(n_estimators=100, random_state=101, n_jobs=-1),\n",
    "    'CatBoost': CatBoostClassifier(verbose=0, random_state=101),\n",
    "    'LightGBM': LGBMClassifier(verbose=-1, random_state=101, n_jobs=-1),\n",
    "    'XGBoost': XGBClassifier(eval_metric='logloss', random_state=101, n_jobs=-1)\n",
    "}\n",
    "\n",
    "# Define combinations\n",
    "combinations = [\n",
    "    ((350, 500), (600, 750)),   \n",
    "]\n",
    "\n",
    "# Initialize results dataframe\n",
    "df1 = pd.DataFrame()\n",
    "\n",
    "# Evaluate and collect results for the specific file\n",
    "file_path = \"C:/Users/saich/Downloads/TSS zip/TSS/Mycobacterium tuberculosis H37Rv.txt\"\n",
    "results_df = evaluate_classifiers(file_path, combinations, classifiers)\n",
    "print(f\"Results for file: {file_path}\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "df1 = pd.concat([df1, results_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for file: C:/Users/saich/Downloads/TSS zip/TSS/Escherichia coli str. K-12 substr. MG1655.txt\n",
      "         Classifier Pos_Range Neg_Range  Accuracy  Precision   Recall  F1 Score                                  Organism\n",
      "                SVM   350-500   600-750  0.676030   0.686047 0.657993  0.671727 Escherichia coli str. K-12 substr. MG1655\n",
      "      Random Forest   350-500   600-750  0.653558   0.664062 0.631970  0.647619 Escherichia coli str. K-12 substr. MG1655\n",
      "Logistic Regression   350-500   600-750  0.634831   0.642308 0.620818  0.631380 Escherichia coli str. K-12 substr. MG1655\n",
      "        Naive Bayes   350-500   600-750  0.705993   0.727642 0.665428  0.695146 Escherichia coli str. K-12 substr. MG1655\n",
      "               K-NN   350-500   600-750  0.513109   0.527273 0.323420  0.400922 Escherichia coli str. K-12 substr. MG1655\n",
      "  Gradient Boosting   350-500   600-750  0.644195   0.657371 0.613383  0.634615 Escherichia coli str. K-12 substr. MG1655\n",
      "           AdaBoost   350-500   600-750  0.616105   0.625000 0.594796  0.609524 Escherichia coli str. K-12 substr. MG1655\n",
      "      Decision Tree   350-500   600-750  0.567416   0.572519 0.557621  0.564972 Escherichia coli str. K-12 substr. MG1655\n",
      "         Perceptron   350-500   600-750  0.601124   0.604478 0.602230  0.603352 Escherichia coli str. K-12 substr. MG1655\n",
      "                SGD   350-500   600-750  0.541199   0.544118 0.550186  0.547135 Escherichia coli str. K-12 substr. MG1655\n",
      "            Bagging   350-500   600-750  0.676030   0.680451 0.672862  0.676636 Escherichia coli str. K-12 substr. MG1655\n",
      "        Extra Trees   350-500   600-750  0.681648   0.700405 0.643123  0.670543 Escherichia coli str. K-12 substr. MG1655\n",
      "           CatBoost   350-500   600-750  0.683521   0.692308 0.669145  0.680529 Escherichia coli str. K-12 substr. MG1655\n",
      "           LightGBM   350-500   600-750  0.632959   0.642023 0.613383  0.627376 Escherichia coli str. K-12 substr. MG1655\n",
      "            XGBoost   350-500   600-750  0.623596   0.630769 0.609665  0.620038 Escherichia coli str. K-12 substr. MG1655\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron, SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from itertools import product\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def transform_sequence(sequence):\n",
    "    length = len(sequence)\n",
    "    total1 = 0\n",
    "    for i in range(length - 1):\n",
    "        sequence2 = sequence[i + 1:]\n",
    "        length2 = len(sequence2)\n",
    "        count1 = sum(1 for j in range(length2) if sequence[j] == sequence2[j])\n",
    "        total1 += (count1 % length2) * 100\n",
    "    \n",
    "    total1 = (total1 / (length - 1)) * 100 if length > 1 else 0\n",
    "    return total1\n",
    "\n",
    "def generate_trimers():\n",
    "    bases = ['A', 'C', 'G', 'T']\n",
    "    return [''.join(p) for p in product(bases, repeat=3)]\n",
    "\n",
    "def transform_sequence_kmer(sequence):\n",
    "    return [transform_sequence(sequence[i:i + 6]) for i in range(len(sequence) - 6)]\n",
    "\n",
    "def load_and_transform_data(file_path, pos_range, neg_range):\n",
    "    with open(file_path, 'r') as file:\n",
    "        sequences = file.read().split('\\n')\n",
    "    pos_sequences = [seq[pos_range[0]-1:pos_range[1]] for seq in sequences if len(seq) >= pos_range[1]]\n",
    "    neg_sequences = [seq[neg_range[0]-1:neg_range[1]] for seq in sequences if len(seq) >= neg_range[1]]\n",
    "    pos_data = pd.DataFrame([transform_sequence_kmer(seq) for seq in pos_sequences])\n",
    "    neg_data = pd.DataFrame([transform_sequence_kmer(seq) for seq in neg_sequences])\n",
    "    \n",
    "    pos_data['label'] = 1\n",
    "    neg_data['label'] = 0\n",
    "    data = pd.concat([pos_data, neg_data], ignore_index=True)\n",
    "    \n",
    "    X = np.array(data.drop('label', axis=1).values.tolist())\n",
    "    y = data['label'].values\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def train_and_save_models(file_path, combinations, classifiers):\n",
    "    results = []\n",
    "    organism_name = os.path.splitext(os.path.basename(file_path))[0]  # Extract organism name from file path\n",
    "    output_dir = f\"models/{organism_name}\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    for pos_range, neg_range in combinations:\n",
    "        X, y = load_and_transform_data(file_path, pos_range, neg_range)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)\n",
    "        \n",
    "        for name, clf in classifiers.items():\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            \n",
    "            model_path = os.path.join(output_dir, f\"{name}.pkl\")\n",
    "            with open(model_path, 'wb') as model_file:\n",
    "                pickle.dump(clf, model_file)\n",
    "            \n",
    "            results.append({\n",
    "                'Classifier': name,\n",
    "                'Pos_Range': f\"{pos_range[0]}-{pos_range[1]}\",\n",
    "                'Neg_Range': f\"{neg_range[0]}-{neg_range[1]}\",\n",
    "                'Accuracy': accuracy_score(y_test, y_pred),\n",
    "                'Precision': precision_score(y_test, y_pred, zero_division=0),\n",
    "                'Recall': recall_score(y_test, y_pred, zero_division=0),\n",
    "                'F1 Score': f1_score(y_test, y_pred, zero_division=0),\n",
    "                'Organism': organism_name\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Classifier definitions\n",
    "classifiers = {\n",
    "    'SVM': SVC(probability=True, random_state=101),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=101, n_jobs=-1),\n",
    "    'Logistic Regression': LogisticRegression(random_state=101, max_iter=500),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'K-NN': KNeighborsClassifier(n_neighbors=5),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=101),\n",
    "    'AdaBoost': AdaBoostClassifier(n_estimators=100, random_state=101),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=101),\n",
    "    'Perceptron': Perceptron(random_state=101),\n",
    "    'SGD': SGDClassifier(random_state=101),\n",
    "    'Bagging': BaggingClassifier(n_estimators=100, random_state=101),\n",
    "    'Extra Trees': ExtraTreesClassifier(n_estimators=100, random_state=101, n_jobs=-1),\n",
    "    'CatBoost': CatBoostClassifier(verbose=0, random_state=101),\n",
    "    'LightGBM': LGBMClassifier(verbose=-1, random_state=101, n_jobs=-1),\n",
    "    'XGBoost': XGBClassifier(eval_metric='logloss', random_state=101, n_jobs=-1)\n",
    "}\n",
    "\n",
    "# Define combinations\n",
    "combinations = [\n",
    "    ((350, 500), (600, 750)),   \n",
    "]\n",
    "\n",
    "# Example usage\n",
    "file_path = \"C:/Users/saich/Downloads/TSS zip/TSS/Escherichia coli str. K-12 substr. MG1655.txt\"\n",
    "results_df = train_and_save_models(file_path, combinations, classifiers)\n",
    "print(f\"Results for file: {file_path}\")\n",
    "print(results_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for file: C:/Users/saich/Downloads/TSS zip/TSS/Escherichia coli str. K-12 substr. MG1655.txt\n",
      "         Classifier  Accuracy  Precision   Recall  F1 Score                                  Organism\n",
      "                SVM  0.676030   0.687500 0.654275  0.670476 Escherichia coli str. K-12 substr. MG1655\n",
      "      Random Forest  0.659176   0.670588 0.635688  0.652672 Escherichia coli str. K-12 substr. MG1655\n",
      "Logistic Regression  0.632959   0.639847 0.620818  0.630189 Escherichia coli str. K-12 substr. MG1655\n",
      "        Naive Bayes  0.705993   0.727642 0.665428  0.695146 Escherichia coli str. K-12 substr. MG1655\n",
      "               K-NN  0.524345   0.543860 0.345725  0.422727 Escherichia coli str. K-12 substr. MG1655\n",
      "  Gradient Boosting  0.646067   0.660000 0.613383  0.635838 Escherichia coli str. K-12 substr. MG1655\n",
      "           AdaBoost  0.616105   0.625000 0.594796  0.609524 Escherichia coli str. K-12 substr. MG1655\n",
      "      Decision Tree  0.573034   0.577358 0.568773  0.573034 Escherichia coli str. K-12 substr. MG1655\n",
      "         Perceptron  0.522472   0.620690 0.133829  0.220183 Escherichia coli str. K-12 substr. MG1655\n",
      "                SGD  0.513109   0.509677 0.881041  0.645777 Escherichia coli str. K-12 substr. MG1655\n",
      "            Bagging  0.670412   0.679537 0.654275  0.666667 Escherichia coli str. K-12 substr. MG1655\n",
      "        Extra Trees  0.681648   0.700405 0.643123  0.670543 Escherichia coli str. K-12 substr. MG1655\n",
      "           CatBoost  0.683521   0.692308 0.669145  0.680529 Escherichia coli str. K-12 substr. MG1655\n",
      "           LightGBM  0.632959   0.642023 0.613383  0.627376 Escherichia coli str. K-12 substr. MG1655\n",
      "            XGBoost  0.623596   0.630769 0.609665  0.620038 Escherichia coli str. K-12 substr. MG1655\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron, SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from itertools import product\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Ensure Matplotlib does not require GUI\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "def transform_sequence(sequence):\n",
    "    length = len(sequence)\n",
    "    total1 = 0\n",
    "    for i in range(length - 1):\n",
    "        sequence2 = sequence[i + 1:]\n",
    "        length2 = len(sequence2)\n",
    "        count1 = sum(1 for j in range(length2) if sequence[j] == sequence2[j])\n",
    "        total1 += (count1 % length2) * 100\n",
    "    \n",
    "    total1 = (total1 / (length - 1)) * 100 if length > 1 else 0\n",
    "    return total1\n",
    "\n",
    "def generate_trimers():\n",
    "    bases = ['A', 'C', 'G', 'T']\n",
    "    return [''.join(p) for p in product(bases, repeat=3)]\n",
    "\n",
    "def transform_sequence_kmer(sequence):\n",
    "    return [transform_sequence(sequence[i:i + 6]) for i in range(len(sequence) - 6)]\n",
    "\n",
    "def load_and_transform_data(file_path, pos_range, neg_range):\n",
    "    with open(file_path, 'r') as file:\n",
    "        sequences = file.read().split('\\n')\n",
    "    pos_sequences = [seq[pos_range[0]-1:pos_range[1]] for seq in sequences if len(seq) >= pos_range[1]]\n",
    "    neg_sequences = [seq[neg_range[0]-1:neg_range[1]] for seq in sequences if len(seq) >= neg_range[1]]\n",
    "    pos_data = pd.DataFrame([transform_sequence_kmer(seq) for seq in pos_sequences])\n",
    "    neg_data = pd.DataFrame([transform_sequence_kmer(seq) for seq in neg_sequences])\n",
    "    \n",
    "    pos_data['label'] = 1\n",
    "    neg_data['label'] = 0\n",
    "    data = pd.concat([pos_data, neg_data], ignore_index=True)\n",
    "    \n",
    "    X = np.array(data.drop('label', axis=1).values.tolist())\n",
    "    y = data['label'].values\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def save_bar_chart(results_df, metric, output_dir):\n",
    "    \"\"\"Creates and saves a bar chart for the given metric\"\"\"\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(results_df['Classifier'], results_df[metric], color='skyblue')\n",
    "    plt.xlabel('Classifier')\n",
    "    plt.ylabel(metric)\n",
    "    plt.title(f'{metric} Comparison')\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    chart_path = os.path.join(output_dir, f\"{metric}.png\")\n",
    "    plt.savefig(chart_path, bbox_inches='tight')\n",
    "    plt.close()  # Close the figure to prevent overlapping plots\n",
    "\n",
    "def train_and_save_models(file_path, combinations, classifiers):\n",
    "    results = []\n",
    "    organism_name = os.path.splitext(os.path.basename(file_path))[0]  # Extract organism name from file path\n",
    "    \n",
    "    # Paths for models and visualization\n",
    "    model_dir = f\"models/{organism_name}\"\n",
    "    vis_dir = f\"visualization/{organism_name}\"\n",
    "    \n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    os.makedirs(vis_dir, exist_ok=True)\n",
    "    \n",
    "    for pos_range, neg_range in combinations:\n",
    "        X, y = load_and_transform_data(file_path, pos_range, neg_range)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)\n",
    "        \n",
    "        for name, clf in classifiers.items():\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            \n",
    "            model_path = os.path.join(model_dir, f\"{name}.pkl\")\n",
    "            with open(model_path, 'wb') as model_file:\n",
    "                pickle.dump(clf, model_file)\n",
    "            \n",
    "            results.append({\n",
    "                'Classifier': name,\n",
    "                'Accuracy': accuracy_score(y_test, y_pred),\n",
    "                'Precision': precision_score(y_test, y_pred, zero_division=0),\n",
    "                'Recall': recall_score(y_test, y_pred, zero_division=0),\n",
    "                'F1 Score': f1_score(y_test, y_pred, zero_division=0),\n",
    "                'Organism': organism_name\n",
    "            })\n",
    "    \n",
    "    # Convert results to DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # Save visualizations\n",
    "    for metric in [\"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"]:\n",
    "        save_bar_chart(results_df, metric, vis_dir)\n",
    "\n",
    "    return results_df\n",
    "\n",
    "# Classifier definitions\n",
    "classifiers = {\n",
    "    'SVM': SVC(probability=True, random_state=101),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=101, n_jobs=-1),\n",
    "    'Logistic Regression': LogisticRegression(random_state=101, max_iter=500),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'K-NN': KNeighborsClassifier(n_neighbors=5),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=101),\n",
    "    'AdaBoost': AdaBoostClassifier(n_estimators=100, random_state=101),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=101),\n",
    "    'Perceptron': Perceptron(random_state=101),\n",
    "    'SGD': SGDClassifier(random_state=101),\n",
    "    'Bagging': BaggingClassifier(n_estimators=100, random_state=101),\n",
    "    'Extra Trees': ExtraTreesClassifier(n_estimators=100, random_state=101, n_jobs=-1),\n",
    "    'CatBoost': CatBoostClassifier(verbose=0, random_state=101),\n",
    "    'LightGBM': LGBMClassifier(verbose=-1, random_state=101, n_jobs=-1),\n",
    "    'XGBoost': XGBClassifier(eval_metric='logloss', random_state=101, n_jobs=-1)\n",
    "}\n",
    "\n",
    "# Define combinations\n",
    "combinations = [\n",
    "    ((350, 500), (600, 750)),   \n",
    "]\n",
    "\n",
    "# Example usage\n",
    "file_path = \"C:/Users/saich/Downloads/TSS zip/TSS/Escherichia coli str. K-12 substr. MG1655.txt\"\n",
    "results_df = train_and_save_models(file_path, combinations, classifiers)\n",
    "\n",
    "# Display results\n",
    "print(f\"Results for file: {file_path}\")\n",
    "print(results_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "19 columns passed, passed data had 25 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:939\u001b[39m, in \u001b[36m_finalize_columns_and_data\u001b[39m\u001b[34m(content, columns, dtype)\u001b[39m\n\u001b[32m    938\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m939\u001b[39m     columns = \u001b[43m_validate_or_indexify_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    941\u001b[39m     \u001b[38;5;66;03m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:986\u001b[39m, in \u001b[36m_validate_or_indexify_columns\u001b[39m\u001b[34m(content, columns)\u001b[39m\n\u001b[32m    984\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_mi_list \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(columns) != \u001b[38;5;28mlen\u001b[39m(content):  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[32m    985\u001b[39m     \u001b[38;5;66;03m# caller's responsibility to check for this...\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m986\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[32m    987\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(columns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m columns passed, passed data had \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    988\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(content)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m columns\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    989\u001b[39m     )\n\u001b[32m    990\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_mi_list:\n\u001b[32m    991\u001b[39m     \u001b[38;5;66;03m# check if nested list column, length of each sub-list should be equal\u001b[39;00m\n",
      "\u001b[31mAssertionError\u001b[39m: 19 columns passed, passed data had 25 columns",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     11\u001b[39m     list2.append(list3)\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(list3)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlist2\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlist2\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\pandas\\core\\frame.py:851\u001b[39m, in \u001b[36mDataFrame.__init__\u001b[39m\u001b[34m(self, data, index, columns, dtype, copy)\u001b[39m\n\u001b[32m    849\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    850\u001b[39m         columns = ensure_index(columns)\n\u001b[32m--> \u001b[39m\u001b[32m851\u001b[39m     arrays, columns, index = \u001b[43mnested_data_to_arrays\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    852\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[39;49;00m\n\u001b[32m    853\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[39;49;00m\n\u001b[32m    854\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    855\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    856\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m    857\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    858\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    859\u001b[39m     mgr = arrays_to_mgr(\n\u001b[32m    860\u001b[39m         arrays,\n\u001b[32m    861\u001b[39m         columns,\n\u001b[32m   (...)\u001b[39m\u001b[32m    864\u001b[39m         typ=manager,\n\u001b[32m    865\u001b[39m     )\n\u001b[32m    866\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:520\u001b[39m, in \u001b[36mnested_data_to_arrays\u001b[39m\u001b[34m(data, columns, index, dtype)\u001b[39m\n\u001b[32m    517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_named_tuple(data[\u001b[32m0\u001b[39m]) \u001b[38;5;129;01mand\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    518\u001b[39m     columns = ensure_index(data[\u001b[32m0\u001b[39m]._fields)\n\u001b[32m--> \u001b[39m\u001b[32m520\u001b[39m arrays, columns = \u001b[43mto_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    521\u001b[39m columns = ensure_index(columns)\n\u001b[32m    523\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:845\u001b[39m, in \u001b[36mto_arrays\u001b[39m\u001b[34m(data, columns, dtype)\u001b[39m\n\u001b[32m    842\u001b[39m     data = [\u001b[38;5;28mtuple\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[32m    843\u001b[39m     arr = _list_to_arrays(data)\n\u001b[32m--> \u001b[39m\u001b[32m845\u001b[39m content, columns = \u001b[43m_finalize_columns_and_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    846\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m content, columns\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:942\u001b[39m, in \u001b[36m_finalize_columns_and_data\u001b[39m\u001b[34m(content, columns, dtype)\u001b[39m\n\u001b[32m    939\u001b[39m     columns = _validate_or_indexify_columns(contents, columns)\n\u001b[32m    940\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    941\u001b[39m     \u001b[38;5;66;03m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m    944\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(contents) \u001b[38;5;129;01mand\u001b[39;00m contents[\u001b[32m0\u001b[39m].dtype == np.object_:\n\u001b[32m    945\u001b[39m     contents = convert_object_array(contents, dtype=dtype)\n",
      "\u001b[31mValueError\u001b[39m: 19 columns passed, passed data had 25 columns"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "with open(\"C:/Users/saich/Downloads/output (2).txt\") as file:\n",
    "    text=file.read()\n",
    "text=text.replace('\\t',' ')\n",
    "text\n",
    "list1=text.split('\\n')\n",
    "list1\n",
    "list2=[]\n",
    "for string in list1:\n",
    "    list3=string.split(' ')\n",
    "    list2.append(list3)\n",
    "print(list3)\n",
    "df = pd.DataFrame(list2[1:], columns=list2[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 ID\n",
      "19 1\n",
      "19 2\n",
      "19 3\n",
      "19 4\n",
      "19 5\n",
      "19 6\n",
      "19 7\n",
      "19 8\n",
      "19 10\n",
      "19 11\n",
      "19 12\n",
      "19 13\n",
      "19 14\n",
      "19 15\n",
      "19 16\n",
      "19 17\n",
      "19 18\n",
      "19 19\n",
      "19 20\n",
      "19 21\n",
      "19 22\n",
      "19 23\n",
      "19 24\n",
      "19 25\n",
      "19 26\n",
      "19 27\n",
      "19 28\n",
      "19 29\n",
      "19 30\n",
      "19 31\n",
      "19 32\n",
      "19 33\n",
      "19 34\n",
      "19 35\n",
      "19 36\n",
      "19 37\n",
      "19 38\n",
      "19 39\n",
      "19 40\n",
      "19 41\n",
      "19 42\n",
      "19 43\n",
      "19 44\n",
      "19 45\n",
      "19 46\n",
      "19 47\n",
      "19 48\n",
      "19 49\n",
      "19 50\n",
      "19 51\n",
      "19 52\n",
      "19 53\n",
      "19 54\n",
      "19 55\n",
      "19 56\n",
      "19 57\n",
      "19 58\n",
      "19 59\n",
      "19 60\n",
      "19 61\n",
      "19 62\n",
      "19 63\n",
      "19 64\n",
      "19 65\n",
      "19 66\n",
      "19 67\n",
      "19 68\n",
      "19 69\n",
      "19 70\n",
      "19 71\n",
      "19 72\n",
      "19 73\n",
      "19 74\n",
      "19 75\n",
      "19 76\n",
      "19 77\n",
      "19 78\n",
      "19 79\n",
      "19 80\n",
      "19 81\n",
      "19 82\n",
      "19 83\n",
      "19 84\n",
      "19 85\n",
      "19 86\n",
      "19 87\n",
      "19 88\n",
      "19 89\n",
      "19 90\n",
      "19 91\n",
      "19 92\n",
      "19 93\n",
      "19 94\n",
      "19 95\n",
      "19 96\n",
      "19 97\n",
      "19 98\n",
      "19 99\n",
      "19 100\n",
      "19 101\n",
      "19 102\n",
      "19 103\n",
      "19 104\n",
      "19 105\n",
      "19 106\n",
      "19 107\n",
      "19 108\n",
      "19 109\n",
      "19 110\n",
      "19 111\n",
      "19 112\n",
      "19 113\n",
      "19 114\n",
      "19 115\n",
      "19 116\n",
      "19 117\n",
      "19 118\n",
      "19 119\n",
      "19 120\n",
      "19 121\n",
      "19 122\n",
      "19 123\n",
      "19 124\n",
      "19 125\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>PropertyName</th>\n",
       "      <th>AA</th>\n",
       "      <th>AC</th>\n",
       "      <th>AG</th>\n",
       "      <th>AT</th>\n",
       "      <th>CA</th>\n",
       "      <th>CC</th>\n",
       "      <th>CG</th>\n",
       "      <th>CT</th>\n",
       "      <th>GA</th>\n",
       "      <th>GC</th>\n",
       "      <th>GG</th>\n",
       "      <th>GT</th>\n",
       "      <th>TA</th>\n",
       "      <th>TC</th>\n",
       "      <th>TG</th>\n",
       "      <th>TT</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Twist</td>\n",
       "      <td>38.9</td>\n",
       "      <td>31.12</td>\n",
       "      <td>32.15</td>\n",
       "      <td>33.81</td>\n",
       "      <td>41.41</td>\n",
       "      <td>34.96</td>\n",
       "      <td>32.91</td>\n",
       "      <td>32.15</td>\n",
       "      <td>41.31</td>\n",
       "      <td>38.5</td>\n",
       "      <td>34.96</td>\n",
       "      <td>31.12</td>\n",
       "      <td>33.28</td>\n",
       "      <td>41.31</td>\n",
       "      <td>41.41</td>\n",
       "      <td>38.9</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Stackingenergy</td>\n",
       "      <td>-12</td>\n",
       "      <td>-11.8</td>\n",
       "      <td>-11.5</td>\n",
       "      <td>-10.6</td>\n",
       "      <td>-12.3</td>\n",
       "      <td>-9.5</td>\n",
       "      <td>-13.1</td>\n",
       "      <td>-11.5</td>\n",
       "      <td>-11.4</td>\n",
       "      <td>-13.2</td>\n",
       "      <td>-9.5</td>\n",
       "      <td>-11.8</td>\n",
       "      <td>-11.2</td>\n",
       "      <td>-11.4</td>\n",
       "      <td>-12.3</td>\n",
       "      <td>-12</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Rise</td>\n",
       "      <td>3.16</td>\n",
       "      <td>3.41</td>\n",
       "      <td>3.63</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.23</td>\n",
       "      <td>4.08</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.63</td>\n",
       "      <td>3.47</td>\n",
       "      <td>3.81</td>\n",
       "      <td>4.08</td>\n",
       "      <td>3.41</td>\n",
       "      <td>3.21</td>\n",
       "      <td>3.47</td>\n",
       "      <td>3.23</td>\n",
       "      <td>3.16</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Bend</td>\n",
       "      <td>3.07</td>\n",
       "      <td>2.97</td>\n",
       "      <td>2.31</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.58</td>\n",
       "      <td>2.16</td>\n",
       "      <td>2.81</td>\n",
       "      <td>2.31</td>\n",
       "      <td>2.51</td>\n",
       "      <td>3.06</td>\n",
       "      <td>2.16</td>\n",
       "      <td>2.97</td>\n",
       "      <td>6.74</td>\n",
       "      <td>2.51</td>\n",
       "      <td>3.58</td>\n",
       "      <td>3.07</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Tip</td>\n",
       "      <td>1.76</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.87</td>\n",
       "      <td>-1.64</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.35</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.71</td>\n",
       "      <td>2</td>\n",
       "      <td>6.7</td>\n",
       "      <td>1.35</td>\n",
       "      <td>-1.64</td>\n",
       "      <td>1.76</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>121</td>\n",
       "      <td>Flexibility_slide</td>\n",
       "      <td>13.72</td>\n",
       "      <td>9.57</td>\n",
       "      <td>7.58</td>\n",
       "      <td>11.69</td>\n",
       "      <td>1.35</td>\n",
       "      <td>7.36</td>\n",
       "      <td>4.02</td>\n",
       "      <td>7.58</td>\n",
       "      <td>10.28</td>\n",
       "      <td>4.34</td>\n",
       "      <td>7.36</td>\n",
       "      <td>9.57</td>\n",
       "      <td>7.13</td>\n",
       "      <td>10.28</td>\n",
       "      <td>1.35</td>\n",
       "      <td>13.72</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>122</td>\n",
       "      <td>Flexibility_shift</td>\n",
       "      <td>5.35</td>\n",
       "      <td>9.73</td>\n",
       "      <td>8.98</td>\n",
       "      <td>1.13</td>\n",
       "      <td>4.61</td>\n",
       "      <td>5.51</td>\n",
       "      <td>12.13</td>\n",
       "      <td>8.98</td>\n",
       "      <td>5.44</td>\n",
       "      <td>1.98</td>\n",
       "      <td>5.51</td>\n",
       "      <td>9.73</td>\n",
       "      <td>4.28</td>\n",
       "      <td>5.44</td>\n",
       "      <td>4.61</td>\n",
       "      <td>5.35</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>123</td>\n",
       "      <td>Enthalpy</td>\n",
       "      <td>-7.6</td>\n",
       "      <td>-8.4</td>\n",
       "      <td>-7.8</td>\n",
       "      <td>-7.2</td>\n",
       "      <td>-8.5</td>\n",
       "      <td>-8</td>\n",
       "      <td>-10.6</td>\n",
       "      <td>-7.8</td>\n",
       "      <td>-8.2</td>\n",
       "      <td>-9.8</td>\n",
       "      <td>-8</td>\n",
       "      <td>-8.4</td>\n",
       "      <td>-7.2</td>\n",
       "      <td>-8.2</td>\n",
       "      <td>-8.5</td>\n",
       "      <td>-7.6</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>124</td>\n",
       "      <td>Entropy</td>\n",
       "      <td>-21.3</td>\n",
       "      <td>-22.4</td>\n",
       "      <td>-21</td>\n",
       "      <td>-20.4</td>\n",
       "      <td>-22.7</td>\n",
       "      <td>-19.9</td>\n",
       "      <td>-27.2</td>\n",
       "      <td>-21</td>\n",
       "      <td>-22.2</td>\n",
       "      <td>-24.4</td>\n",
       "      <td>-19.9</td>\n",
       "      <td>-22.4</td>\n",
       "      <td>-21.3</td>\n",
       "      <td>-22.2</td>\n",
       "      <td>-22.7</td>\n",
       "      <td>-21.3</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>125</td>\n",
       "      <td>Freeenergy</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.44</td>\n",
       "      <td>-1.28</td>\n",
       "      <td>-0.88</td>\n",
       "      <td>-1.45</td>\n",
       "      <td>-1.84</td>\n",
       "      <td>-2.17</td>\n",
       "      <td>-1.28</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>-2.24</td>\n",
       "      <td>-1.84</td>\n",
       "      <td>-1.44</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>-1.45</td>\n",
       "      <td>-1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>124 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID       PropertyName     AA     AC     AG     AT     CA     CC     CG  \\\n",
       "0      1              Twist   38.9  31.12  32.15  33.81  41.41  34.96  32.91   \n",
       "1      2     Stackingenergy    -12  -11.8  -11.5  -10.6  -12.3   -9.5  -13.1   \n",
       "2      3               Rise   3.16   3.41   3.63   3.89   3.23   4.08    3.6   \n",
       "3      4               Bend   3.07   2.97   2.31    2.6   3.58   2.16   2.81   \n",
       "4      5                Tip   1.76      2    0.9   1.87  -1.64   0.71   0.22   \n",
       "..   ...                ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "119  121  Flexibility_slide  13.72   9.57   7.58  11.69   1.35   7.36   4.02   \n",
       "120  122  Flexibility_shift   5.35   9.73   8.98   1.13   4.61   5.51  12.13   \n",
       "121  123           Enthalpy   -7.6   -8.4   -7.8   -7.2   -8.5     -8  -10.6   \n",
       "122  124            Entropy  -21.3  -22.4    -21  -20.4  -22.7  -19.9  -27.2   \n",
       "123  125         Freeenergy     -1  -1.44  -1.28  -0.88  -1.45  -1.84  -2.17   \n",
       "\n",
       "        CT     GA     GC     GG     GT     TA     TC     TG     TT     \n",
       "0    32.15  41.31   38.5  34.96  31.12  33.28  41.31  41.41   38.9     \n",
       "1    -11.5  -11.4  -13.2   -9.5  -11.8  -11.2  -11.4  -12.3    -12     \n",
       "2     3.63   3.47   3.81   4.08   3.41   3.21   3.47   3.23   3.16     \n",
       "3     2.31   2.51   3.06   2.16   2.97   6.74   2.51   3.58   3.07     \n",
       "4      0.9   1.35    2.5   0.71      2    6.7   1.35  -1.64   1.76     \n",
       "..     ...    ...    ...    ...    ...    ...    ...    ...    ... ..  \n",
       "119   7.58  10.28   4.34   7.36   9.57   7.13  10.28   1.35  13.72     \n",
       "120   8.98   5.44   1.98   5.51   9.73   4.28   5.44   4.61   5.35     \n",
       "121   -7.8   -8.2   -9.8     -8   -8.4   -7.2   -8.2   -8.5   -7.6     \n",
       "122    -21  -22.2  -24.4  -19.9  -22.4  -21.3  -22.2  -22.7  -21.3     \n",
       "123  -1.28   -1.3  -2.24  -1.84  -1.44  -0.58   -1.3  -1.45     -1     \n",
       "\n",
       "[124 rows x 19 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "text=text.replace('\\t',' ')\n",
    "text\n",
    "list1=text.split('\\n')\n",
    "list1\n",
    "list2=[]\n",
    "for string in list1:\n",
    "    list3=string.split(' ')\n",
    "    list2.append(list3)\n",
    "list2=list2[:126]\n",
    "list2.pop(9)\n",
    "for i in list2:\n",
    "    print(len(i),i[0])\n",
    "pd.DataFrame(data=list2[1:],columns=list2[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for file: C:/Users/saich/Downloads/TSS zip/TSS/Haloferax_volcanii_DS2.txt\n",
      "         Classifier  Accuracy  Precision   Recall  F1 Score               Organism\n",
      "                SVM  0.684701   0.700000 0.666667  0.682927 Haloferax_volcanii_DS2\n",
      "      Random Forest  0.710821   0.739837 0.666667  0.701349 Haloferax_volcanii_DS2\n",
      "Logistic Regression  0.680970   0.690299 0.677656  0.683919 Haloferax_volcanii_DS2\n",
      "        Naive Bayes  0.686567   0.727273 0.615385  0.666667 Haloferax_volcanii_DS2\n",
      "               K-NN  0.555970   0.631579 0.307692  0.413793 Haloferax_volcanii_DS2\n",
      "  Gradient Boosting  0.722015   0.744094 0.692308  0.717268 Haloferax_volcanii_DS2\n",
      "           AdaBoost  0.682836   0.710204 0.637363  0.671815 Haloferax_volcanii_DS2\n",
      "      Decision Tree  0.617537   0.615646 0.663004  0.638448 Haloferax_volcanii_DS2\n",
      "         Perceptron  0.520522   0.515152 0.996337  0.679151 Haloferax_volcanii_DS2\n",
      "                SGD  0.604478   0.587896 0.747253  0.658065 Haloferax_volcanii_DS2\n",
      "            Bagging  0.694030   0.715415 0.663004  0.688213 Haloferax_volcanii_DS2\n",
      "        Extra Trees  0.694030   0.715415 0.663004  0.688213 Haloferax_volcanii_DS2\n",
      "           CatBoost  0.727612   0.747082 0.703297  0.724528 Haloferax_volcanii_DS2\n",
      "           LightGBM  0.697761   0.698925 0.714286  0.706522 Haloferax_volcanii_DS2\n",
      "            XGBoost  0.680970   0.682143 0.699634  0.690778 Haloferax_volcanii_DS2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier,\n",
    "    BaggingClassifier, ExtraTreesClassifier\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron, SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from itertools import product\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Ensure Matplotlib does not require GUI\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "def transform_sequence(sequence):\n",
    "    \"\"\"Transforms a sequence into a numerical representation.\"\"\"\n",
    "    length = len(sequence)\n",
    "    total1 = 0\n",
    "    for i in range(length - 1):\n",
    "        sequence2 = sequence[i + 1:]\n",
    "        length2 = len(sequence2)\n",
    "        count1 = sum(1 for j in range(length2) if sequence[j] == sequence2[j])\n",
    "        total1 += (count1 % length2) * 100\n",
    "    \n",
    "    total1 = (total1 / (length - 1)) * 100 if length > 1 else 0\n",
    "    return total1\n",
    "\n",
    "def generate_trimers():\n",
    "    \"\"\"Generates all possible trimers of DNA bases.\"\"\"\n",
    "    bases = ['A', 'C', 'G', 'T']\n",
    "    return [''.join(p) for p in product(bases, repeat=3)]\n",
    "\n",
    "def transform_sequence_kmer(sequence):\n",
    "    \"\"\"Applies transformation to k-mer slices of the sequence.\"\"\"\n",
    "    return [transform_sequence(sequence[i:i + 6]) for i in range(len(sequence) - 6 + 1)]\n",
    "\n",
    "def load_and_transform_data(file_path, pos_range, neg_range):\n",
    "    with open(file_path, 'r') as file:\n",
    "        sequences = file.read().split('\\n')\n",
    "    pos_sequences = [seq[pos_range[0]-1:pos_range[1]] for seq in sequences if len(seq) >= pos_range[1]]\n",
    "    neg_sequences = [seq[neg_range[0]-1:neg_range[1]] for seq in sequences if len(seq) >= neg_range[1]]\n",
    "    pos_data = pd.DataFrame([transform_sequence_kmer(seq) for seq in pos_sequences])\n",
    "    neg_data = pd.DataFrame([transform_sequence_kmer(seq) for seq in neg_sequences])\n",
    "    \n",
    "    pos_data['label'] = 1\n",
    "    neg_data['label'] = 0\n",
    "    data = pd.concat([pos_data, neg_data], ignore_index=True)\n",
    "    \n",
    "    X = np.array(data.drop('label', axis=1).values.tolist())\n",
    "    y = data['label'].values\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def save_model(clf, model_path, model_type):\n",
    "    \"\"\"Saves models in the appropriate format based on type.\"\"\"\n",
    "    if model_type == 'XGBoost':\n",
    "        clf.save_model(model_path + \".json\")\n",
    "    elif model_type == 'CatBoost':\n",
    "        clf.save_model(model_path + \".cbm\")\n",
    "    else:\n",
    "        with open(model_path + \".pkl\", 'wb') as model_file:\n",
    "            pickle.dump(clf, model_file)\n",
    "\n",
    "def save_bar_chart(results_df, metric, output_dir):\n",
    "    \"\"\"Creates and saves a bar chart for a given metric.\"\"\"\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(results_df['Classifier'], results_df[metric], color='skyblue')\n",
    "    plt.xlabel('Classifier')\n",
    "    plt.ylabel(metric)\n",
    "    plt.title(f'{metric} Comparison')\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    chart_path = os.path.join(output_dir, f\"{metric}.png\")\n",
    "    plt.savefig(chart_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def train_and_save_models(file_path, combinations, classifiers):\n",
    "    \"\"\"Trains models, saves them in compatible formats, and generates evaluation results.\"\"\"\n",
    "    results = []\n",
    "    organism_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    \n",
    "    # Paths for models and visualization\n",
    "    model_dir = f\"models/{organism_name}\"\n",
    "    vis_dir = f\"visualization/{organism_name}\"\n",
    "    \n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    os.makedirs(vis_dir, exist_ok=True)\n",
    "    \n",
    "    for pos_range, neg_range in combinations:\n",
    "        X, y = load_and_transform_data(file_path, pos_range, neg_range)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)\n",
    "        \n",
    "        for name, clf in classifiers.items():\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            \n",
    "            model_path = os.path.join(model_dir, name)\n",
    "            save_model(clf, model_path, name)\n",
    "            \n",
    "            results.append({\n",
    "                'Classifier': name,\n",
    "                'Accuracy': accuracy_score(y_test, y_pred),\n",
    "                'Precision': precision_score(y_test, y_pred, zero_division=0),\n",
    "                'Recall': recall_score(y_test, y_pred, zero_division=0),\n",
    "                'F1 Score': f1_score(y_test, y_pred, zero_division=0),\n",
    "                'Organism': organism_name\n",
    "            })\n",
    "    \n",
    "    # Convert results to DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # Save visualizations\n",
    "    for metric in [\"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"]:\n",
    "        save_bar_chart(results_df, metric, vis_dir)\n",
    "\n",
    "    return results_df\n",
    "\n",
    "# Classifier definitions\n",
    "classifiers = {\n",
    "    'SVM': SVC(probability=True, random_state=101),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=101, n_jobs=-1),\n",
    "    'Logistic Regression': LogisticRegression(random_state=101, max_iter=500),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'K-NN': KNeighborsClassifier(n_neighbors=5),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=101),\n",
    "    'AdaBoost': AdaBoostClassifier(n_estimators=100, random_state=101),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=101),\n",
    "    'Perceptron': Perceptron(random_state=101),\n",
    "    'SGD': SGDClassifier(random_state=101),\n",
    "    'Bagging': BaggingClassifier(n_estimators=100, random_state=101),\n",
    "    'Extra Trees': ExtraTreesClassifier(n_estimators=100, random_state=101, n_jobs=-1),\n",
    "    'CatBoost': CatBoostClassifier(verbose=0, random_state=101),\n",
    "    'LightGBM': LGBMClassifier(verbose=-1, random_state=101, n_jobs=-1),\n",
    "    'XGBoost': XGBClassifier(eval_metric='logloss', random_state=101, n_jobs=-1)\n",
    "}\n",
    "\n",
    "# Define combinations\n",
    "combinations = [\n",
    "    ((350, 499), (600, 749)),  # 150 bases each\n",
    "]\n",
    "\n",
    "# Example usage\n",
    "file_path =\"C:/Users/saich/Downloads/TSS zip/TSS/Haloferax_volcanii_DS2.txt\"\n",
    "results_df = train_and_save_models(file_path, combinations, classifiers)\n",
    "\n",
    "# Display results\n",
    "print(f\"Results for file: {file_path}\")\n",
    "print(results_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier,\n",
    "    BaggingClassifier, ExtraTreesClassifier\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron, SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from itertools import product\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Ensure Matplotlib does not require GUI\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "def transform_sequence(sequence):\n",
    "    \"\"\"Transforms a sequence into a numerical representation.\"\"\"\n",
    "    length = len(sequence)\n",
    "    total1 = 0\n",
    "    for i in range(length - 1):\n",
    "        sequence2 = sequence[i + 1:]\n",
    "        length2 = len(sequence2)\n",
    "        count1 = sum(1 for j in range(length2) if sequence[j] == sequence2[j])\n",
    "        total1 += (count1 % length2) * 100\n",
    "    \n",
    "    total1 = (total1 / (length - 1)) * 100 if length > 1 else 0\n",
    "    return total1\n",
    "\n",
    "def generate_trimers():\n",
    "    \"\"\"Generates all possible trimers of DNA bases.\"\"\"\n",
    "    bases = ['A', 'C', 'G', 'T']\n",
    "    return [''.join(p) for p in product(bases, repeat=3)]\n",
    "\n",
    "def transform_sequence_kmer(sequence):\n",
    "    \"\"\"Applies transformation to k-mer slices of the sequence.\"\"\"\n",
    "    return [transform_sequence(sequence[i:i + 6]) for i in range(len(sequence) - 6 + 1)]\n",
    "\n",
    "def load_and_transform_data(file_path, pos_range, neg_range):\n",
    "    with open(file_path, 'r') as file:\n",
    "        sequences = file.read().split('\\n')\n",
    "    pos_sequences = [seq[pos_range[0]-1:pos_range[1]] for seq in sequences if len(seq) >= pos_range[1]]\n",
    "    neg_sequences = [seq[neg_range[0]-1:neg_range[1]] for seq in sequences if len(seq) >= neg_range[1]]\n",
    "    pos_data = pd.DataFrame([transform_sequence_kmer(seq) for seq in pos_sequences])\n",
    "    neg_data = pd.DataFrame([transform_sequence_kmer(seq) for seq in neg_sequences])\n",
    "    \n",
    "    pos_data['label'] = 1\n",
    "    neg_data['label'] = 0\n",
    "    data = pd.concat([pos_data, neg_data], ignore_index=True)\n",
    "    \n",
    "    X = np.array(data.drop('label', axis=1).values.tolist())\n",
    "    y = data['label'].values\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def save_model(clf, model_path, model_type):\n",
    "    \"\"\"Saves models in the appropriate format based on type.\"\"\"\n",
    "    if model_type == 'XGBoost':\n",
    "        clf.save_model(model_path + \".json\")\n",
    "    elif model_type == 'CatBoost':\n",
    "        clf.save_model(model_path + \".cbm\")\n",
    "    else:\n",
    "        with open(model_path + \".pkl\", 'wb') as model_file:\n",
    "            pickle.dump(clf, model_file)\n",
    "\n",
    "def save_bar_chart(results_df, metric, output_dir):\n",
    "    \"\"\"Creates and saves a bar chart for a given metric.\"\"\"\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(results_df['Classifier'], results_df[metric], color='skyblue')\n",
    "    plt.xlabel('Classifier')\n",
    "    plt.ylabel(metric)\n",
    "    plt.title(f'{metric} Comparison')\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    chart_path = os.path.join(output_dir, f\"{metric}.png\")\n",
    "    plt.savefig(chart_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def train_and_save_models(file_path, combinations, classifiers):\n",
    "    \"\"\"Trains models, saves them in compatible formats, and generates evaluation results.\"\"\"\n",
    "    results = []\n",
    "    organism_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    \n",
    "    # Paths for models and visualization\n",
    "    model_dir = f\"models/{organism_name}\"\n",
    "    vis_dir = f\"visualization/{organism_name}\"\n",
    "    \n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    os.makedirs(vis_dir, exist_ok=True)\n",
    "    \n",
    "    for pos_range, neg_range in combinations:\n",
    "        X, y = load_and_transform_data(file_path, pos_range, neg_range)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)\n",
    "        \n",
    "        for name, clf in classifiers.items():\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            \n",
    "            model_path = os.path.join(model_dir, name)\n",
    "            save_model(clf, model_path, name)\n",
    "            \n",
    "            results.append({\n",
    "                'Classifier': name,\n",
    "                'Accuracy': accuracy_score(y_test, y_pred),\n",
    "                'Precision': precision_score(y_test, y_pred, zero_division=0),\n",
    "                'Recall': recall_score(y_test, y_pred, zero_division=0),\n",
    "                'F1 Score': f1_score(y_test, y_pred, zero_division=0),\n",
    "                'Organism': organism_name\n",
    "            })\n",
    "    \n",
    "    # Convert results to DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # Save visualizations\n",
    "    for metric in [\"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"]:\n",
    "        save_bar_chart(results_df, metric, vis_dir)\n",
    "\n",
    "    return results_df\n",
    "\n",
    "# Classifier definitions\n",
    "classifiers = {\n",
    "    'SVM': SVC(probability=True, random_state=101),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=101, n_jobs=-1),\n",
    "    'Logistic Regression': LogisticRegression(random_state=101, max_iter=500),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'K-NN': KNeighborsClassifier(n_neighbors=5),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=101),\n",
    "    'AdaBoost': AdaBoostClassifier(n_estimators=100, random_state=101),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=101),\n",
    "    'Perceptron': Perceptron(random_state=101),\n",
    "    'SGD': SGDClassifier(random_state=101),\n",
    "    'Bagging': BaggingClassifier(n_estimators=100, random_state=101),\n",
    "    'Extra Trees': ExtraTreesClassifier(n_estimators=100, random_state=101, n_jobs=-1),\n",
    "    'CatBoost': CatBoostClassifier(verbose=0, random_state=101),\n",
    "    'LightGBM': LGBMClassifier(verbose=-1, random_state=101, n_jobs=-1),\n",
    "    'XGBoost': XGBClassifier(eval_metric='logloss', random_state=101, n_jobs=-1)\n",
    "}\n",
    "\n",
    "# Define combinations\n",
    "combinations = [\n",
    "    ((350, 499), (600, 749)),  # 150 bases each\n",
    "]\n",
    "\n",
    "# Example usage\n",
    "file_path =\"C:/Users/saich/Downloads/TSS zip/TSS/Haloferax_volcanii_DS2.txt\"\n",
    "text=text.replace('\\t',' ')\n",
    "text\n",
    "list1=text.split('\\n')\n",
    "list1\n",
    "list2=[]\n",
    "for string in list1:\n",
    "    list3=string.split(' ')\n",
    "    list2.append(list3)\n",
    "list2=list2[:126]\n",
    "list2.pop(9)\n",
    "for i in list2:\n",
    "    print(len(i),i[0])\n",
    "df1=pd.DataFrame(data=list2[1:],columns=list2[0])\n",
    "colums=['AA','AC','AG','AT','CA','CC','CG','CT','GA','GC','GG','GT','TA','TC','TG','TT']\n",
    "results_df = train_and_save_models(file_path, combinations, classifiers)\n",
    "# Display results\n",
    "print(f\"Results for file: {file_path}\")\n",
    "print(results_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\saich\\OneDrive\\Desktop\\project\\my_env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier,\n",
    "    BaggingClassifier, ExtraTreesClassifier\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron, SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def encode_sequence(sequence, property_name, df1):\n",
    "    \"\"\"Encodes a DNA sequence using a 2-mer sliding window based on a property column in df1.\"\"\"\n",
    "    encoded_values = []\n",
    "    for i in range(len(sequence) - 1):\n",
    "        pair = sequence[i:i + 2]  # Extract 2-mer\n",
    "        if pair in df1.columns:\n",
    "            encoded_values.append(float(df1.loc[property_name, pair]))  # Fix lookup\n",
    "        else:\n",
    "            encoded_values.append(0)  # Default value if pair not found\n",
    "    return encoded_values\n",
    "\n",
    "def load_and_transform_data(file_path, pos_range, neg_range, property_name, df1):\n",
    "    \"\"\"Loads sequences, encodes them using the selected property, and prepares training data.\"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        sequences = file.read().split('\\n')\n",
    "    \n",
    "    pos_sequences = [seq[pos_range[0]-1:pos_range[1]] for seq in sequences if len(seq) >= pos_range[1]]\n",
    "    neg_sequences = [seq[neg_range[0]-1:neg_range[1]] for seq in sequences if len(seq) >= neg_range[1]]\n",
    "    \n",
    "    pos_data = pd.DataFrame([encode_sequence(seq, property_name, df1) for seq in pos_sequences])\n",
    "    neg_data = pd.DataFrame([encode_sequence(seq, property_name, df1) for seq in neg_sequences])\n",
    "    \n",
    "    pos_data['label'] = 1\n",
    "    neg_data['label'] = 0\n",
    "    data = pd.concat([pos_data, neg_data], ignore_index=True)\n",
    "    \n",
    "    X = np.array(data.drop('label', axis=1).values.tolist())\n",
    "    y = data['label'].values\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def save_model(clf, model_path):\n",
    "    \"\"\"Saves a trained model to a file.\"\"\"\n",
    "    with open(model_path, 'wb') as model_file:\n",
    "        pickle.dump(clf, model_file)\n",
    "\n",
    "def train_models(file_path, combinations, classifiers, df1):\n",
    "    \"\"\"Trains models for each property, selects the best one, and saves all models for that property.\"\"\"\n",
    "    organism_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    best_accuracy = 0\n",
    "    best_property = None\n",
    "    best_models = {}\n",
    "    best_results = []\n",
    "\n",
    "    # Iterate over all properties in df1\n",
    "    for property_name in df1.index:  # Use index instead of columns\n",
    "        for pos_range, neg_range in combinations:\n",
    "            X, y = load_and_transform_data(file_path, pos_range, neg_range, property_name, df1)\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)\n",
    "            \n",
    "            models = {}\n",
    "            results = []\n",
    "            for name, clf in classifiers.items():\n",
    "                clf.fit(X_train, y_train)\n",
    "                y_pred = clf.predict(X_test)\n",
    "                accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "                # Store model and its results\n",
    "                models[name] = clf\n",
    "                results.append({\n",
    "                    'Classifier': name,\n",
    "                    'Accuracy': accuracy,\n",
    "                    'Precision': precision_score(y_test, y_pred, zero_division=0),\n",
    "                    'Recall': recall_score(y_test, y_pred, zero_division=0),\n",
    "                    'F1 Score': f1_score(y_test, y_pred, zero_division=0),\n",
    "                    'Organism': organism_name,\n",
    "                    'Property': property_name\n",
    "                })\n",
    "\n",
    "                # Update best property if a higher accuracy is found\n",
    "                if accuracy > best_accuracy:\n",
    "                    best_accuracy = accuracy\n",
    "                    best_property = property_name\n",
    "                    best_models = models  # Save all models for this property\n",
    "                    best_results = results  # Save results for this property\n",
    "\n",
    "    # Save all models for the best property\n",
    "    if best_models:\n",
    "        model_dir = f\"models/{organism_name}/{best_property}\"\n",
    "        os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "        for model_name, clf in best_models.items():\n",
    "            model_path = os.path.join(model_dir, f\"{model_name}.pkl\")\n",
    "            save_model(clf, model_path)\n",
    "\n",
    "        # Save the best property-organism mapping\n",
    "        with open(\"best_properties.txt\", \"a\") as f:\n",
    "            f.write(f\"{organism_name}: {best_property}\\n\")\n",
    "\n",
    "        # Save the results to a CSV file\n",
    "        results_df = pd.DataFrame(best_results)\n",
    "        results_csv = f\"models/{organism_name}/best_models_metrics.csv\"\n",
    "        results_df.to_csv(results_csv, index=False)\n",
    "\n",
    "    return best_property\n",
    "\n",
    "# Load dataset for encoding\n",
    "text = text.replace('\\t', ' ')\n",
    "list1 = text.split('\\n')\n",
    "list2 = [line.split(' ') for line in list1[:126]]\n",
    "list2.pop(9)  # Ensure correct data structure\n",
    "\n",
    "df1 = pd.DataFrame(data=list2[1:], columns=list2[0])  # No index creation\n",
    "df1.set_index(df1.columns[0], inplace=True)  # Set first column as index\n",
    "\n",
    "# Define classifier models\n",
    "classifiers = {\n",
    "    'SVM': SVC(probability=True, random_state=101),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=101, n_jobs=-1),\n",
    "    'Logistic Regression': LogisticRegression(random_state=101, max_iter=500),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'K-NN': KNeighborsClassifier(n_neighbors=5),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=101),\n",
    "    'AdaBoost': AdaBoostClassifier(n_estimators=100, random_state=101),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=101),\n",
    "    'Perceptron': Perceptron(random_state=101),\n",
    "    'SGD': SGDClassifier(random_state=101),\n",
    "    'Bagging': BaggingClassifier(n_estimators=100, random_state=101),\n",
    "    'Extra Trees': ExtraTreesClassifier(n_estimators=100, random_state=101, n_jobs=-1),\n",
    "    'CatBoost': CatBoostClassifier(verbose=0, random_state=101),\n",
    "    'LightGBM': LGBMClassifier(verbose=-1, random_state=101, n_jobs=-1),\n",
    "    'XGBoost': XGBClassifier(eval_metric='logloss', random_state=101, n_jobs=-1)\n",
    "}\n",
    "\n",
    "# Define segment combinations\n",
    "combinations = [((350, 499), (600, 749))]\n",
    "\n",
    "# Example usage\n",
    "file_path = \"C:/Users/saich/Downloads/TSS zip/TSS/Haloferax_volcanii_DS2.txt\"\n",
    "best_property = train_models(file_path, combinations, classifiers, df1)\n",
    "print(f\"Best property saved for {file_path}: {best_property}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
